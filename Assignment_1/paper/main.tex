\documentclass{article}

\input{settings.tex}



\begin{document}
\selectlanguage{swedish}

\input{title.tex}



\section*{Problem 1}
\subsection*{1.1}

TODO:
Change to 
\begin{equation}
(x_i-\mu)^{T}(x_i-\mu)
\end{equation}

\begin{equation}
L = p(x|\mu,\sigma^2I) = \prod_{i=1}^n \sim  {N}(x_i|\mu,\sigma^2I)
\label{eq:likelihood}
\end{equation}
%\noindent To find the maximum likelihood the likelihood function has to be differentiated w.r.t $\sigma$. To make the derivation simpler the logarithm is taken to get the log likelihood function described in equation~\ref{eq:loglike}
%\begin{equation}
%log(L) = %Nlog(\frac{1}{2\pi^{}D/2}\frac{1}{|\sigma^2I|^{1/2}}) - %\frac{1}{2}\Sigma_{n=1}^N(x_n-\mu)^T(%\sigma^2I)^{-1}(x_n-\mu)
%\label{eq:loglike}
%\end{equation}


\noindent Knowing that the distribuition is spherical the maxmimum likelihood estimator for $\sigma$ will be the same in all directions. Thus the log likelihood function can be represented as described in equation~\ref{eq:loglike}
\begin{equation}
log(L) =-\frac{1}{2\sigma^2}\Sigma_{i=1}^n(x_i-\mu)^2 - \frac{n}{2}log(\sigma^2) - \frac{n}{2}log(2\pi)
\label{eq:loglike}
\end{equation}
and by differentiating equation~\ref{eq:loglike} w.r.t $\sigma$ equation~\ref{eq:diff} is aquired
\begin{equation}
	\frac{\delta log(L)}{\delta \sigma} = \frac{1}{\sigma^3}\Sigma_{i=1}^n(x_i-\mu)^T(x_i-\mu) - \frac{n}{\sigma}
	\label{eq:diff}
\end{equation}
and solving equation~\ref{eq:diff} for zero the maximum likelihood is gathered and described in equation~\ref{eq:ML}
\begin{equation}
	\sigma_{ML}^2 = \frac{1}{n}\Sigma_{i=1}^n(x_i-\mu)^T(x_i-\mu),
	\label{eq:ML}
\end{equation}

as the second derivative,

\begin{equation}
\begin{array}{rcl}
\left.\frac{\delta^2 log(L)}{\delta\sigma^2}\right|_{\sigma^2=\sigma_{ML}^2} & = & -\frac{3}{\sigma^4_{ML}}\Sigma_{i=1}^{n}(x_i-\mu)^T(x_i-\mu)+\frac{2n}{\sigma^2_{ML}}\\
& = & -\frac{1}{\sigma^4_{ML}}\Sigma_{i=1}^{n}(x_i-\mu)^T(x_i-\mu) < 0,
\end{array}
\end{equation}

is negative at that point and the maximum is therefore found.

\subsection*{1.2}

\subsubsection*{a)}
To derive the posterior distribution the probability distribution and the inverse-gamma prior distribution are multiplied. 

$$ P(X =x|\sigma^2) P(\sigma^2=s|\alpha , \beta) = \frac{1}{2\pi \sigma^2} exp(-\frac{(x - \mu)^Tx-\mu}{2\sigma^2}) $$
 
answer:
\begin{equation}
P(\sigma^2=s|\mu and stuff) \propto InverseGamma(\alpha+1, \beta + \sum(x-\mu)^{T}(x-\mu))
\end{equation}

\subsubsection*{b)}

\begin{equation}
B_{Factor}=\frac{P(\sigma^2=s|M_A)}{P(\sigma^2=s|M_B)}
\end{equation}

where
\begin{equation}
P(M_A|D)=\frac{P(D|M_A)P(M_A)}{P(D)}
\end{equation}

so that

\begin{equation}
B_{Factor} = \frac{P(M_A|D)P(M_B) }{P(M_B|D)P(M_A)}
\end{equation}



\subsubsection*{c)}

\begin{equation}
B_{Factor}=\frac{P(M_A|\sigma^2=\sigma_{ML}^2)}{P(M_B|\sigma^2=\sigma_{ML}^2)}
\end{equation}

\newpage 

\section*{Problem 2}
\subsection*{Problem 2.1}
Figure~\ref{fig:prob21} shows the plotted data and how the data lies within the circles. Note that the data points within the circles almost correspond with 1,2 and 3 standard deviations, as should be expected from a normal distribution. 
\begin{figure}[H]
	\centering
	\includegraphics[width=0.65\textwidth]{Figures/plot2_1_scatter.png}
	\caption{\label{fig:prob21}}
\end{figure}

\subsection*{Problem 2.2}



\end{document}
